{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf46ca-c60a-4539-8275-5024e386d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ann\n",
    "import scanpy as sc\n",
    "import os, sys\n",
    "from scipy.stats import pearsonr as pr\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.metrics import precision_recall_curve as prc\n",
    "from sklearn.metrics import silhouette_score as sil\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c030da4-c665-4606-a71f-0a68621f0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cad76-c20a-40e4-b8ed-4aa043939b14",
   "metadata": {},
   "source": [
    "# Load Anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b998efb8-31f7-4d26-9087-57bc5e8168a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang3712/.local/lib/python3.8/site-packages/anndata/_core/anndata.py:1838: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 259 × 1512\n",
       "    obs: 'Tissue', 'prim_or_metas', 'metas_site'\n",
       "    var: 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'hvg', 'log1p'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "adata = sc.read('METMAP500.h5ad')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f189cd-acd9-4b24-b13f-e912a5c591ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BOWEL', 'SKIN', 'LUNG', 'BLADDER', 'BRAIN', 'PANCREAS', 'OVARY',\n",
       "       'KIDNEY', 'HEAD AND NECK', 'UTERUS', 'LIVER', 'BREAST',\n",
       "       'ESOPHAGUS'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reformat the tissue as just the name\n",
    "from collections import Counter\n",
    "all_tissues = adata.obs['Tissue'].unique()\n",
    "new_tissues = []\n",
    "for tissue in adata.obs['Tissue']:\n",
    "    if tissue.startswith('CNS/BRAIN'):\n",
    "        new_tissues.append('BRAIN')\n",
    "    else:\n",
    "        new_tissues.append(tissue.split('/')[0].split('_')[0])\n",
    "adata.obs['new_tissue'] = new_tissues\n",
    "adata.obs['new_tissue'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16906518-791c-4f37-a0cc-626670aa5b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db37c445-0210-43e2-be03-e848c7690649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the labels\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    unique_labels = list(set(labels))\n",
    "    \n",
    "    one_hot_encoded = np.zeros(shape=(len(labels), num_classes))\n",
    "\n",
    "    # Encode labels by setting the corresponding index to 1 in each row\n",
    "    for i, label in enumerate(labels):\n",
    "        index = unique_labels.index(label)\n",
    "        one_hot_encoded[i, index] = 1\n",
    "\n",
    "    return one_hot_encoded, unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dfe580-8700-414b-9cd2-c3c4503ff84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels_tissue,_ = one_hot_encode(adata.obs['new_tissue'], len(adata.obs['new_tissue'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a5c266-9db0-4ae9-a118-dd2f85925ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels_site, uniqe_labels_site = one_hot_encode(adata.obs['metas_site'], len(adata.obs['metas_site'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a6b14-0070-44be-adcc-200cd9f73ba6",
   "metadata": {},
   "source": [
    "## One vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55dc6f9f-f5ea-434d-a042-8d4a9da255d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg\n",
      "kidney\n",
      "liver\n",
      "bone\n",
      "lung\n",
      "brain\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels_site_one_vs_all = dict()\n",
    "all_sites = adata.obs.metas_site.value_counts().index\n",
    "for tissue in all_sites:\n",
    "    print(tissue)\n",
    "    tissues_to_learn = tissue\n",
    "    one_vs_all_labels = []\n",
    "    for i in adata.obs.metas_site:\n",
    "        if  i == tissues_to_learn:\n",
    "            one_vs_all_labels.append(1)\n",
    "        else:\n",
    "            one_vs_all_labels.append(0)\n",
    "    adata.obs[tissue+'.1va'] = one_vs_all_labels\n",
    "    one_hot_labels_site_one_vs_all[tissue], _ = one_hot_encode(adata.obs[tissue+'.1va'], len(adata.obs[tissue+'.1va'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67955aa-1197-4b27-8a88-423bef9a0875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tissue</th>\n",
       "      <th>prim_or_metas</th>\n",
       "      <th>metas_site</th>\n",
       "      <th>new_tissue</th>\n",
       "      <th>Neg.1va</th>\n",
       "      <th>kidney.1va</th>\n",
       "      <th>liver.1va</th>\n",
       "      <th>bone.1va</th>\n",
       "      <th>lung.1va</th>\n",
       "      <th>brain.1va</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACH-000007</th>\n",
       "      <td>BOWEL</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Neg</td>\n",
       "      <td>BOWEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000008</th>\n",
       "      <td>SKIN</td>\n",
       "      <td>Primary</td>\n",
       "      <td>liver</td>\n",
       "      <td>SKIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000012</th>\n",
       "      <td>LUNG</td>\n",
       "      <td>Primary</td>\n",
       "      <td>bone</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000015</th>\n",
       "      <td>LUNG</td>\n",
       "      <td>Primary</td>\n",
       "      <td>liver</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000018</th>\n",
       "      <td>BLADDER/URINARY TRACT</td>\n",
       "      <td>Primary</td>\n",
       "      <td>brain</td>\n",
       "      <td>BLADDER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000996</th>\n",
       "      <td>UTERUS</td>\n",
       "      <td>Primary</td>\n",
       "      <td>bone</td>\n",
       "      <td>UTERUS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000997</th>\n",
       "      <td>BOWEL</td>\n",
       "      <td>Primary</td>\n",
       "      <td>lung</td>\n",
       "      <td>BOWEL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001016</th>\n",
       "      <td>CNS/BRAIN</td>\n",
       "      <td>Primary</td>\n",
       "      <td>kidney</td>\n",
       "      <td>BRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001113</th>\n",
       "      <td>LUNG</td>\n",
       "      <td>Primary</td>\n",
       "      <td>brain</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001318</th>\n",
       "      <td>LIVER</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Neg</td>\n",
       "      <td>LIVER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Tissue prim_or_metas metas_site new_tissue  \\\n",
       "ACH-000007                  BOWEL       Primary        Neg      BOWEL   \n",
       "ACH-000008                   SKIN       Primary      liver       SKIN   \n",
       "ACH-000012                   LUNG       Primary       bone       LUNG   \n",
       "ACH-000015                   LUNG       Primary      liver       LUNG   \n",
       "ACH-000018  BLADDER/URINARY TRACT       Primary      brain    BLADDER   \n",
       "...                           ...           ...        ...        ...   \n",
       "ACH-000996                 UTERUS       Primary       bone     UTERUS   \n",
       "ACH-000997                  BOWEL       Primary       lung      BOWEL   \n",
       "ACH-001016              CNS/BRAIN       Primary     kidney      BRAIN   \n",
       "ACH-001113                   LUNG       Primary      brain       LUNG   \n",
       "ACH-001318                  LIVER       Primary        Neg      LIVER   \n",
       "\n",
       "            Neg.1va  kidney.1va  liver.1va  bone.1va  lung.1va  brain.1va  \n",
       "ACH-000007        1           0          0         0         0          0  \n",
       "ACH-000008        0           0          1         0         0          0  \n",
       "ACH-000012        0           0          0         1         0          0  \n",
       "ACH-000015        0           0          1         0         0          0  \n",
       "ACH-000018        0           0          0         0         0          1  \n",
       "...             ...         ...        ...       ...       ...        ...  \n",
       "ACH-000996        0           0          0         1         0          0  \n",
       "ACH-000997        0           0          0         0         1          0  \n",
       "ACH-001016        0           1          0         0         0          0  \n",
       "ACH-001113        0           0          0         0         0          1  \n",
       "ACH-001318        1           0          0         0         0          0  \n",
       "\n",
       "[259 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb27c4-03ce-4634-b2f9-009579303d71",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54deb7ee-23bf-4a29-83ab-d2dd24b487f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f80143c-8c22-4c5f-8348-c2ceec7e5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneExpressionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tumors, metas_sites):\n",
    "        self.data = data  # gene expression data (shape: N x num_genes)\n",
    "        self.tumors = tumors  # primary tumor type\n",
    "        self.site = metas_sites # metastasis sites\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        expression = self.data[idx]  # single gene expression vector\n",
    "        tumor = self.tumors[idx]  \n",
    "        site = self.site[idx]\n",
    "        return expression, tumor, site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d86ed7-cfdf-4fdb-b5fc-a578928122c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001617</th>\n",
       "      <th>ENSG00000001626</th>\n",
       "      <th>ENSG00000002586</th>\n",
       "      <th>ENSG00000002726</th>\n",
       "      <th>ENSG00000002822</th>\n",
       "      <th>ENSG00000003147</th>\n",
       "      <th>ENSG00000003402</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000259207</th>\n",
       "      <th>ENSG00000261052</th>\n",
       "      <th>ENSG00000264424</th>\n",
       "      <th>ENSG00000271503</th>\n",
       "      <th>ENSG00000275385</th>\n",
       "      <th>ENSG00000275410</th>\n",
       "      <th>ENSG00000275718</th>\n",
       "      <th>ENSG00000275896</th>\n",
       "      <th>ENSG00000277443</th>\n",
       "      <th>ENSG00000277586</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACH-000007</th>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.418544</td>\n",
       "      <td>0.369698</td>\n",
       "      <td>0.106475</td>\n",
       "      <td>0.408904</td>\n",
       "      <td>0.474120</td>\n",
       "      <td>0.458151</td>\n",
       "      <td>0.440864</td>\n",
       "      <td>0.464034</td>\n",
       "      <td>0.260111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.279958</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.068780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219731</td>\n",
       "      <td>0.493214</td>\n",
       "      <td>0.421571</td>\n",
       "      <td>0.273935</td>\n",
       "      <td>0.049319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000008</th>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.477888</td>\n",
       "      <td>0.343918</td>\n",
       "      <td>0.017110</td>\n",
       "      <td>0.016921</td>\n",
       "      <td>0.478341</td>\n",
       "      <td>0.010205</td>\n",
       "      <td>0.480758</td>\n",
       "      <td>0.066012</td>\n",
       "      <td>0.335006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545344</td>\n",
       "      <td>0.276866</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.127957</td>\n",
       "      <td>0.065129</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.222305</td>\n",
       "      <td>0.393855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000012</th>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.456729</td>\n",
       "      <td>0.308974</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.381573</td>\n",
       "      <td>0.035220</td>\n",
       "      <td>0.272343</td>\n",
       "      <td>0.308789</td>\n",
       "      <td>0.430792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112426</td>\n",
       "      <td>0.328580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372882</td>\n",
       "      <td>0.002864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000015</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.451050</td>\n",
       "      <td>0.317799</td>\n",
       "      <td>0.103040</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.413896</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.338382</td>\n",
       "      <td>0.172822</td>\n",
       "      <td>0.322058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024053</td>\n",
       "      <td>0.230060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280227</td>\n",
       "      <td>0.057089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000018</th>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.479226</td>\n",
       "      <td>0.263913</td>\n",
       "      <td>0.387343</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.644546</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.399677</td>\n",
       "      <td>0.156312</td>\n",
       "      <td>0.350153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242461</td>\n",
       "      <td>0.310473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.421349</td>\n",
       "      <td>0.004805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000996</th>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.440487</td>\n",
       "      <td>0.295306</td>\n",
       "      <td>0.185086</td>\n",
       "      <td>0.048008</td>\n",
       "      <td>0.288487</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.286848</td>\n",
       "      <td>0.340713</td>\n",
       "      <td>0.236046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164890</td>\n",
       "      <td>0.289611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233327</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.080224</td>\n",
       "      <td>0.190480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-000997</th>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.544124</td>\n",
       "      <td>0.340695</td>\n",
       "      <td>0.161163</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>0.531133</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.303902</td>\n",
       "      <td>0.374838</td>\n",
       "      <td>0.413348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.287474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218204</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.249225</td>\n",
       "      <td>0.006531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001016</th>\n",
       "      <td>0.034719</td>\n",
       "      <td>0.436016</td>\n",
       "      <td>0.333444</td>\n",
       "      <td>0.196966</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>0.571435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217110</td>\n",
       "      <td>0.375106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490580</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001113</th>\n",
       "      <td>0.086371</td>\n",
       "      <td>0.221148</td>\n",
       "      <td>0.484695</td>\n",
       "      <td>0.234437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387764</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.227263</td>\n",
       "      <td>0.124448</td>\n",
       "      <td>0.373009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076591</td>\n",
       "      <td>0.368189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509043</td>\n",
       "      <td>0.410519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACH-001318</th>\n",
       "      <td>0.122032</td>\n",
       "      <td>0.552614</td>\n",
       "      <td>0.399020</td>\n",
       "      <td>0.100679</td>\n",
       "      <td>0.244568</td>\n",
       "      <td>0.583287</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.259647</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>0.405115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.259348</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.044802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275655</td>\n",
       "      <td>0.385757</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.420451</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 1512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ENSG00000000971  ENSG00000001036  ENSG00000001084  \\\n",
       "ACH-000007         0.001362         0.418544         0.369698   \n",
       "ACH-000008         0.006430         0.477888         0.343918   \n",
       "ACH-000012         0.191250         0.456729         0.308974   \n",
       "ACH-000015         0.257558         0.451050         0.317799   \n",
       "ACH-000018         0.153213         0.479226         0.263913   \n",
       "...                     ...              ...              ...   \n",
       "ACH-000996         0.074882         0.440487         0.295306   \n",
       "ACH-000997         0.003535         0.544124         0.340695   \n",
       "ACH-001016         0.034719         0.436016         0.333444   \n",
       "ACH-001113         0.086371         0.221148         0.484695   \n",
       "ACH-001318         0.122032         0.552614         0.399020   \n",
       "\n",
       "            ENSG00000001617  ENSG00000001626  ENSG00000002586  \\\n",
       "ACH-000007         0.106475         0.408904         0.474120   \n",
       "ACH-000008         0.017110         0.016921         0.478341   \n",
       "ACH-000012         0.020991         0.001036         0.381573   \n",
       "ACH-000015         0.103040         0.004082         0.413896   \n",
       "ACH-000018         0.387343         0.000931         0.644546   \n",
       "...                     ...              ...              ...   \n",
       "ACH-000996         0.185086         0.048008         0.288487   \n",
       "ACH-000997         0.161163         0.027014         0.531133   \n",
       "ACH-001016         0.196966         0.012406         0.571435   \n",
       "ACH-001113         0.234437         0.000000         0.387764   \n",
       "ACH-001318         0.100679         0.244568         0.583287   \n",
       "\n",
       "            ENSG00000002726  ENSG00000002822  ENSG00000003147  \\\n",
       "ACH-000007         0.458151         0.440864         0.464034   \n",
       "ACH-000008         0.010205         0.480758         0.066012   \n",
       "ACH-000012         0.035220         0.272343         0.308789   \n",
       "ACH-000015         0.000636         0.338382         0.172822   \n",
       "ACH-000018         0.009856         0.399677         0.156312   \n",
       "...                     ...              ...              ...   \n",
       "ACH-000996         0.006353         0.286848         0.340713   \n",
       "ACH-000997         0.003096         0.303902         0.374838   \n",
       "ACH-001016         0.000000         0.319017         0.000000   \n",
       "ACH-001113         0.007274         0.227263         0.124448   \n",
       "ACH-001318         0.004671         0.259647         0.163008   \n",
       "\n",
       "            ENSG00000003402  ...  ENSG00000259207  ENSG00000261052  \\\n",
       "ACH-000007         0.260111  ...         0.001478         0.279958   \n",
       "ACH-000008         0.335006  ...         0.545344         0.276866   \n",
       "ACH-000012         0.430792  ...         0.112426         0.328580   \n",
       "ACH-000015         0.322058  ...         0.024053         0.230060   \n",
       "ACH-000018         0.350153  ...         0.242461         0.310473   \n",
       "...                     ...  ...              ...              ...   \n",
       "ACH-000996         0.236046  ...         0.164890         0.289611   \n",
       "ACH-000997         0.413348  ...         0.011084         0.287474   \n",
       "ACH-001016         0.367459  ...         0.217110         0.375106   \n",
       "ACH-001113         0.373009  ...         0.076591         0.368189   \n",
       "ACH-001318         0.405115  ...         0.009119         0.259348   \n",
       "\n",
       "            ENSG00000264424  ENSG00000271503  ENSG00000275385  \\\n",
       "ACH-000007         0.017318         0.068780         0.000000   \n",
       "ACH-000008         0.001148         0.127957         0.065129   \n",
       "ACH-000012         0.000000         0.033411         0.000000   \n",
       "ACH-000015         0.000000         0.024011         0.000000   \n",
       "ACH-000018         0.000000         0.144101         0.000000   \n",
       "...                     ...              ...              ...   \n",
       "ACH-000996         0.000000         0.085934         0.000000   \n",
       "ACH-000997         0.000000         0.000000         0.000000   \n",
       "ACH-001016         0.000000         0.005349         0.000000   \n",
       "ACH-001113         0.000000         0.019027         0.000000   \n",
       "ACH-001318         0.000826         0.044802         0.000000   \n",
       "\n",
       "            ENSG00000275410  ENSG00000275718  ENSG00000275896  \\\n",
       "ACH-000007         0.219731         0.493214         0.421571   \n",
       "ACH-000008         0.003036         0.007540         0.011576   \n",
       "ACH-000012         0.325642         0.004284         0.000000   \n",
       "ACH-000015         0.002155         0.005483         0.000000   \n",
       "ACH-000018         0.274338         0.000000         0.088571   \n",
       "...                     ...              ...              ...   \n",
       "ACH-000996         0.233327         0.004805         0.080224   \n",
       "ACH-000997         0.218204         0.030232         0.003117   \n",
       "ACH-001016         0.000000         0.000000         0.000000   \n",
       "ACH-001113         0.000000         0.000000         0.000000   \n",
       "ACH-001318         0.275655         0.385757         0.012241   \n",
       "\n",
       "            ENSG00000277443  ENSG00000277586  \n",
       "ACH-000007         0.273935         0.049319  \n",
       "ACH-000008         0.222305         0.393855  \n",
       "ACH-000012         0.372882         0.002864  \n",
       "ACH-000015         0.280227         0.057089  \n",
       "ACH-000018         0.421349         0.004805  \n",
       "...                     ...              ...  \n",
       "ACH-000996         0.190480         0.000000  \n",
       "ACH-000997         0.249225         0.006531  \n",
       "ACH-001016         0.490580         0.000862  \n",
       "ACH-001113         0.509043         0.410519  \n",
       "ACH-001318         0.420451         0.004654  \n",
       "\n",
       "[259 rows x 1512 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min max normalization\n",
    "df_normalized = adata.to_df().apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=1)\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a705d86-c64d-47b7-8ece-3a5bbbdc6650",
   "metadata": {},
   "source": [
    "# Stratified Five fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56acd1ee-a028-4a39-87dd-84763a94034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = GeneExpressionDataset(torch.tensor(df_normalized.to_numpy(), dtype=torch.float32), \n",
    "                                 torch.tensor(one_hot_labels_tissue, dtype=torch.float32),\n",
    "                                 torch.tensor(one_hot_labels_site, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d370325a-2791-49a1-9a18-55f12de62985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Validation Tissue Labels: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12]), array([4, 3, 1, 6, 3, 5, 5, 6, 5, 4, 3, 7])) 12\n",
      "Validation Site Labels: (array([0, 1, 2, 3, 4, 5]), array([ 5, 11, 15,  7,  8,  6])) 6\n",
      "Fold 2\n",
      "Validation Tissue Labels: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), array([ 5,  6,  2,  3,  1, 13,  3,  2,  2,  8,  2,  3,  2])) 13\n",
      "Validation Site Labels: (array([0, 1, 2, 3, 4, 5]), array([ 5, 11, 15,  7,  8,  6])) 6\n",
      "Fold 3\n",
      "Validation Tissue Labels: (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]), array([ 7,  4,  3,  2,  2,  9,  2,  2, 10,  2,  5,  4])) 12\n",
      "Validation Site Labels: (array([0, 1, 2, 3, 4, 5]), array([ 5, 11, 14,  8,  8,  6])) 6\n",
      "Fold 4\n",
      "Validation Tissue Labels: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), array([2, 5, 5, 3, 1, 9, 7, 2, 2, 5, 3, 4, 4])) 13\n",
      "Validation Site Labels: (array([0, 1, 2, 3, 4, 5]), array([ 5, 11, 14,  8,  8,  6])) 6\n",
      "Fold 5\n",
      "Validation Tissue Labels: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]), array([1, 3, 4, 7, 4, 8, 1, 4, 2, 8, 1, 4, 4])) 13\n",
      "Validation Site Labels: (array([0, 1, 2, 3, 4, 5]), array([ 6, 11, 14,  7,  8,  5])) 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# Convert to class indices\n",
    "tissue_labels = np.argmax(one_hot_labels_tissue, axis=1)  # Convert one-hot to class indices\n",
    "site_labels = np.argmax(one_hot_labels_site, axis=1)  # Convert one-hot to class indices\n",
    "\n",
    "# Prepare StratifiedKFold\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)  # Use a fixed random_state for repeatability\n",
    "\n",
    "# Store seeds and indices\n",
    "cv_splits = []\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# Iterate through the splits\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_normalized.to_numpy(), site_labels)):\n",
    "    # print(train_idx)\n",
    "    # print(val_idx)\n",
    "    print(f'Fold {fold+1}')\n",
    "    \n",
    "    # Extract the training and validation data based on the indices\n",
    "    train_data = torch.utils.data.Subset(all_data, train_idx)\n",
    "    val_data = torch.utils.data.Subset(all_data, val_idx)\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    cv_splits.append({'train_idx': train_idx, 'val_idx': val_idx})\n",
    "    \n",
    "    # Check stratification by printing unique labels in the validation set\n",
    "    val_tissue_labels = np.argmax(one_hot_labels_tissue[val_idx], axis=1)\n",
    "    val_site_labels = np.argmax(one_hot_labels_site[val_idx], axis=1)\n",
    "    \n",
    "    print('Validation Tissue Labels:', np.unique(val_tissue_labels, return_counts=True), len(np.unique(val_tissue_labels)))\n",
    "    print('Validation Site Labels:', np.unique(val_site_labels, return_counts=True), len(np.unique(val_site_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61432bf8-fc49-4132-a54a-a5566f3ebf02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PreMet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56bd6b0-fb79-4989-b2fc-2f4a47f0f782",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb36d158-d802-43de-8052-0d7a5a46a089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_weights_xavier(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)  # Xavier initialization\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight)  # Xavier initialization\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9198c0-3578-4eea-ad11-d431604080d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, gene_num, latent_size, hidden_dim=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(gene_num, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2_mean = nn.Linear(hidden_dim, latent_size)\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_size)\n",
    "        # Apply Xavier initialization\n",
    "        self.apply(initialize_weights_xavier)  \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # switch to leaky RELU\n",
    "        h = F.leaky_relu(self.bn1(self.fc1(x)), negative_slope=0.01)\n",
    "        mean = self.fc2_mean(h)\n",
    "        logvar = self.fc2_logvar(h)\n",
    "        return mean, logvar\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size, gene_num, hidden_dim=128):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_size, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, gene_num)\n",
    "        # Apply Xavier initialization\n",
    "        self.apply(initialize_weights_xavier)  \n",
    "        \n",
    "    def forward(self, z):\n",
    "        h = F.leaky_relu(self.bn1(self.fc1(z)))\n",
    "        reconstructed_x = self.fc2(h)  \n",
    "        return reconstructed_x\n",
    "\n",
    "\n",
    "\n",
    "class Primary_tumor_DNN(nn.Module):\n",
    "    def __init__(self, num_latent, num_classes):\n",
    "        super(Primary_tumor_DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_latent, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        #  x = self.fc3(x)  \n",
    "        return self.softmax(x)\n",
    "\n",
    "\n",
    "class Metas_site_DNN(nn.Module):\n",
    "    def __init__(self, num_latent, num_classes):\n",
    "        super(Metas_site_DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_latent, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        #  x = self.fc3(x)  \n",
    "        return self.softmax(x)\n",
    "    \n",
    "# Define the VAE\n",
    "\n",
    "class PreMet(nn.Module):\n",
    "    def __init__(self, gene_num, latent_size, num_tissues, num_metas_sites, hidden_size):\n",
    "        super(PreMet, self).__init__()\n",
    "        self.encoder = Encoder(gene_num, latent_size, hidden_dim=hidden_size)\n",
    "        self.decoder = Decoder(latent_size, gene_num, hidden_dim=hidden_size)\n",
    "        self.tissue_nn = Primary_tumor_DNN(latent_size, num_tissues)\n",
    "        self.site_nn = Metas_site_DNN(latent_size, num_metas_sites)\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mean + eps * std\n",
    "        else:\n",
    "            return mean\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        \n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        reconstructed_x = self.decoder(z)\n",
    "        \n",
    "        # predict tumor type from latent\n",
    "        tissue_output = self.tissue_nn(z)\n",
    "        \n",
    "        # predict metastasis site from latent\n",
    "        site_output = self.site_nn(z)\n",
    "        \n",
    "        return reconstructed_x, mean, logvar, tissue_output, site_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65bf9e96-bdd8-4e7c-9637-7c47eb38807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def premet_predict(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # print(data)\n",
    "            data = data[0].to(next(model.parameters()).device)  # Ensure data is on the same device as the model\n",
    "            mean, logvar = model.encoder(data)\n",
    "            z = model.reparameterize(mean, logvar)\n",
    "            labels = model.site_nn(z)\n",
    "            # print(labels)\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "    all_labels = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5a5e3-a092-450a-b61b-feac89bb68b5",
   "metadata": {},
   "source": [
    "# Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96604291-6cf9-4709-a5cf-2fd417e42399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy', 'auc', 'auprc', 'avg', 'f1_score']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha = 0.25\n",
    "best_gamma = 4\n",
    "best_model_dir = '/depot/natallah/data/Luopin/Metestasis/5fold_CV_model_focal_loss_alpha'+str(best_alpha)+'_gamma'+str(best_gamma)+'/'\n",
    "all_best_models = os.listdir(best_model_dir)\n",
    "all_best_models.sort()\n",
    "\n",
    "all_metrics = set()\n",
    "\n",
    "for m in all_best_models:\n",
    "    all_metrics.add(m.split('.')[-2])\n",
    "all_metrics = list(all_metrics)\n",
    "all_metrics.sort()\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97dbd50-760a-467c-8798-78043376e766",
   "metadata": {},
   "source": [
    "### PreMet-VAE (last row in Table 3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96c81654-9508-43f5-ad79-2d0b242f29b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_prediction_metric_dict = dict()\n",
    "prior_prediction_metric_dict = dict()\n",
    "\n",
    "all_ground_truth_dfs = dict()\n",
    "all_prediction_value_dfs = dict()\n",
    "\n",
    "for metric_idx in range(len(all_metrics)):\n",
    "    final_prediction_metric_dict[all_metrics[metric_idx]] = dict()\n",
    "    prior_prediction_metric_dict[all_metrics[metric_idx]] = dict()\n",
    "    all_ground_truth_dfs[all_metrics[metric_idx]] = dict()\n",
    "    all_prediction_value_dfs[all_metrics[metric_idx]] = dict()\n",
    "    \n",
    "    fold = 1\n",
    "    prior_accuracies = []\n",
    "    prior_f1_scores = []\n",
    "    prior_aurocs = []\n",
    "    prior_auprcs = []\n",
    "\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "\n",
    "    for split in cv_splits:\n",
    "        # print('*' * 10, fold, '*' * 10)\n",
    "        \n",
    "        all_ground_truth_dfs[all_metrics[metric_idx]][fold] = dict()\n",
    "        all_prediction_value_dfs[all_metrics[metric_idx]][fold] = dict()\n",
    "\n",
    "        all_data = GeneExpressionDataset(torch.tensor(df_normalized.to_numpy(), dtype=torch.float32), \n",
    "                                        torch.tensor(one_hot_labels_tissue, dtype=torch.float32),\n",
    "                                        torch.tensor(one_hot_labels_site, dtype=torch.float32))\n",
    "        # Extract the training and validation data based on the indices\n",
    "        val_data = torch.utils.data.Subset(all_data, split['val_idx'])\n",
    "        val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)        \n",
    "\n",
    "        # load the best model for different metrics\n",
    "\n",
    "        for metric in [all_metrics[metric_idx]]:\n",
    "            # print('+' * 10, metric, '+' * 10)\n",
    "            best_models = dict()\n",
    "            # load the model\n",
    "            for site in all_sites:\n",
    "                # print('$' * 10, site, '$' * 10)\n",
    "                model = PreMet(gene_num=adata.n_vars, latent_size=32, \n",
    "                                num_tissues=len(adata.obs['new_tissue'].unique()),\n",
    "                                num_metas_sites=len(adata.obs[tissue + '.1va'].unique()),\n",
    "                                hidden_size=64)\n",
    "\n",
    "                model.load_state_dict(torch.load(best_model_dir + site + '.split_' + str(fold) + '.' + metric + '.pth'))\n",
    "                best_models[site] = model\n",
    "                \"\"\"\n",
    "                for name, param in model.named_parameters():\n",
    "                    print(f\"Parameter: {name}, Size: {param.size()}\")\n",
    "                    print(param.data)\n",
    "                    break\n",
    "                \"\"\"\n",
    "\n",
    "            predictions = dict()\n",
    "            ground_truth_dfs = adata.obs.iloc[split['val_idx']]\n",
    "            for site in all_sites:\n",
    "                preds = premet_predict(best_models[site], val_dataloader)\n",
    "                # the second column indicates sample predicted to be this label\n",
    "                predictions[site] = preds[:, 1]\n",
    "            prediction_df = pd.DataFrame.from_dict(predictions)\n",
    "            new_names = [s + '.1va' for s in all_sites]\n",
    "            ground_truth_dfs = ground_truth_dfs[new_names]\n",
    "            \n",
    "            # save the predictions and ground truth for confusionmatrix\n",
    "            all_ground_truth_dfs[all_metrics[metric_idx]][fold] = ground_truth_dfs\n",
    "            all_prediction_value_dfs[all_metrics[metric_idx]][fold] = prediction_df\n",
    "\n",
    "            # Convert the DataFrames to numpy arrays\n",
    "            true_labels = ground_truth_dfs.to_numpy()\n",
    "            pred_probs = prediction_df.to_numpy()\n",
    "\n",
    "            # Calculate priors\n",
    "\n",
    "            # Convert one-hot encoded labels to class indices\n",
    "            true_labels_val = np.argmax(true_labels, axis=1)\n",
    "\n",
    "            # Calculate the class distribution\n",
    "            class_counts = np.bincount(true_labels_val)\n",
    "            total_samples = len(true_labels_val)\n",
    "            most_frequent_class = class_counts.max()\n",
    "\n",
    "            # Prior Accuracy: The frequency of the most common class\n",
    "            prior_accuracy = most_frequent_class / total_samples\n",
    "\n",
    "            # Prior F1 Score: Macro F1 score assuming all samples are predicted as the most frequent class\n",
    "            dummy_predictions = np.full_like(true_labels_val, fill_value=np.argmax(class_counts))  # Predicting the most frequent class for all\n",
    "            prior_f1_score = f1(true_labels_val, dummy_predictions, average='macro')\n",
    "\n",
    "            # Prior AUROC: This will be 0.5 for random guessing in multi-class problems (you can calculate class-wise AUROC if needed)\n",
    "            prior_auroc = 0.5\n",
    "\n",
    "            # Prior AUPRC: Class-wise AUPRC (One-vs-Rest)\n",
    "            prior_auprc = average_precision_score(np.eye(len(class_counts))[true_labels_val], np.eye(len(class_counts))[dummy_predictions], average='macro')\n",
    "\n",
    "            # Store prior metrics\n",
    "            prior_accuracies.append(prior_accuracy)\n",
    "            prior_f1_scores.append(prior_f1_score)\n",
    "            prior_aurocs.append(prior_auroc)\n",
    "            prior_auprcs.append(prior_auprc)\n",
    "\n",
    "            # Print prior metrics\n",
    "            \"\"\"\n",
    "            print(f'Prior Accuracy: {prior_accuracy:.4f}')\n",
    "            print(f'Prior F1 Score: {prior_f1_score:.4f}')\n",
    "            print(f'Prior AUROC: {prior_auroc:.4f}')\n",
    "            print(f'Prior AUPRC: {prior_auprc:.4f}')\n",
    "            print('#' * 10)\n",
    "            \"\"\"\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(np.argmax(true_labels, axis=1), np.argmax(pred_probs, axis=1))\n",
    "            f1_score = f1(np.argmax(true_labels, axis=1), np.argmax(pred_probs, axis=1), average='macro')\n",
    "            auroc = roc_auc_score(true_labels, pred_probs, multi_class='ovr')\n",
    "\n",
    "            # Calculate AUPRC for each class and average\n",
    "            precision = dict()\n",
    "            recall = dict()\n",
    "            auprc = []\n",
    "            for i in range(true_labels.shape[1]):\n",
    "                precision[i], recall[i], _ = prc(true_labels[:, i], pred_probs[:, i])\n",
    "                auprc.append(auc(recall[i], precision[i]))\n",
    "            avg_auprc = np.mean(auprc)\n",
    "\n",
    "            # Store metrics\n",
    "            accuracies.append(accuracy)\n",
    "            f1_scores.append(f1_score)\n",
    "            aurocs.append(auroc)\n",
    "            auprcs.append(avg_auprc)\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "    prior_prediction_metric_dict[all_metrics[metric_idx]]['f1'] = prior_f1_scores\n",
    "    prior_prediction_metric_dict[all_metrics[metric_idx]]['accuracy'] = prior_accuracies\n",
    "    prior_prediction_metric_dict[all_metrics[metric_idx]]['auroc'] = prior_aurocs\n",
    "    prior_prediction_metric_dict[all_metrics[metric_idx]]['auprc'] = prior_auprcs\n",
    "        \n",
    "    final_prediction_metric_dict[all_metrics[metric_idx]]['f1'] = f1_scores\n",
    "    final_prediction_metric_dict[all_metrics[metric_idx]]['accuracy'] = accuracies\n",
    "    final_prediction_metric_dict[all_metrics[metric_idx]]['auroc'] = aurocs\n",
    "    final_prediction_metric_dict[all_metrics[metric_idx]]['auprc'] = auprcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cc1f603-03aa-4df4-9f20-a2601152f4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>avg</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.482891</td>\n",
       "      <td>0.409846</td>\n",
       "      <td>0.377033</td>\n",
       "      <td>0.503269</td>\n",
       "      <td>0.502824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.501885</td>\n",
       "      <td>0.459502</td>\n",
       "      <td>0.401735</td>\n",
       "      <td>0.501885</td>\n",
       "      <td>0.521569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auroc</th>\n",
       "      <td>0.707560</td>\n",
       "      <td>0.791326</td>\n",
       "      <td>0.734091</td>\n",
       "      <td>0.766492</td>\n",
       "      <td>0.722608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auprc</th>\n",
       "      <td>0.451378</td>\n",
       "      <td>0.443024</td>\n",
       "      <td>0.549126</td>\n",
       "      <td>0.508891</td>\n",
       "      <td>0.426140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy       auc     auprc       avg  f1_score\n",
       "f1        0.482891  0.409846  0.377033  0.503269  0.502824\n",
       "accuracy  0.501885  0.459502  0.401735  0.501885  0.521569\n",
       "auroc     0.707560  0.791326  0.734091  0.766492  0.722608\n",
       "auprc     0.451378  0.443024  0.549126  0.508891  0.426140"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction_metric_df = pd.DataFrame.from_dict(final_prediction_metric_dict)\n",
    "final_prediction_metric_df\n",
    "final_prediction_metric_avg = []\n",
    "for idx in final_prediction_metric_df.index:\n",
    "    tmp = []\n",
    "    for col in final_prediction_metric_df.columns:\n",
    "        tmp.append(np.mean(final_prediction_metric_df[col].loc[idx]))\n",
    "    final_prediction_metric_avg.append(tmp)\n",
    "\n",
    "final_prediction_metric_avg_df = pd.DataFrame(final_prediction_metric_avg)\n",
    "final_prediction_metric_avg_df.columns =  final_prediction_metric_df.columns\n",
    "final_prediction_metric_avg_df.index =  final_prediction_metric_df.index\n",
    "final_prediction_metric_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b944c11-a647-479b-a594-2800cbc00fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auroc</th>\n",
       "      <th>auprc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.536508</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.793021</td>\n",
       "      <td>0.580597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.558558</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.783910</td>\n",
       "      <td>0.572512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463477</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.745099</td>\n",
       "      <td>0.467925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.463750</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.778282</td>\n",
       "      <td>0.448059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494052</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.732146</td>\n",
       "      <td>0.475363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  accuracy     auroc     auprc\n",
       "0  0.536508  0.519231  0.793021  0.580597\n",
       "1  0.558558  0.557692  0.783910  0.572512\n",
       "2  0.463477  0.480769  0.745099  0.467925\n",
       "3  0.463750  0.461538  0.778282  0.448059\n",
       "4  0.494052  0.490196  0.732146  0.475363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 $0.50\\pm0.04$\n",
      "accuracy $0.50\\pm0.03$\n",
      "auroc $0.77\\pm0.02$\n",
      "auprc $0.51\\pm0.06$\n"
     ]
    }
   ],
   "source": [
    "# we use \"avg\" as the final score across all models, the mean score between f1, acc, roc and prc\n",
    "# this is also what's reported in the paper\n",
    "best_metric = 'avg'\n",
    "best_final_prediction_metrid_df = pd.DataFrame.from_dict(final_prediction_metric_dict[best_metric])\n",
    "display(best_final_prediction_metrid_df)\n",
    "for col in best_final_prediction_metrid_df.columns:\n",
    "    # print(idx)\n",
    "    # tmp = []\n",
    "    tmp = best_final_prediction_metrid_df[col]\n",
    "    # final_prediction_metric_avg.append(tmp)\n",
    "    print(f'{col} ${np.mean(tmp):.2f}\\pm{np.std(tmp):.2f}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9051f-f993-4fe8-813e-dcc6f28d197a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "premet",
   "language": "python",
   "name": "premet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
